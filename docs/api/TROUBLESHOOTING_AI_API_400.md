# üîß ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤ AI API Error 400

## ‚ùå ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö

```
2025-10-07 14:53:28,237 - ai_simple_extraction - WARNING - AI API returned status 400
Exception: AI simple extraction failed after all retries
```

---

## üîç ‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ

### **1. Prompt ‡∏¢‡∏≤‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô Token Limit** ‚ö†Ô∏è ‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏‡∏´‡∏•‡∏±‡∏Å
- ‡πÇ‡∏°‡πÄ‡∏î‡∏• `qwen/qwen3-4b-2507` ‡∏°‡∏µ context window ‡∏à‡∏≥‡∏Å‡∏±‡∏î
- OCR text ‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡πÑ‡∏õ‡∏¢‡∏≤‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
- ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå request: OCR text ‡∏°‡∏µ **1,500+ ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î**

### **2. Request Format ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á**
- Payload format ‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà API ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
- Model name ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á

### **3. API Server ‡∏õ‡∏±‡∏ç‡∏´‡∏≤**
- API server ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏±‡∏ö request ‡πÑ‡∏î‡πâ
- Network timeout

---

## ‚úÖ ‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç

### **‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1: ‡∏•‡∏î Token ‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡πÑ‡∏õ (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥)**

#### **‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç `config.json`**

‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏à‡∏≤‡∏Å:
```json
{
  "ai_extraction": {
    "prompt_optimization": {
      "max_ocr_results": 300
    }
  }
}
```

‡πÄ‡∏õ‡πá‡∏ô:
```json
{
  "ai_extraction": {
    "prompt_optimization": {
      "max_ocr_results": 100
    }
  }
}
```

**‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢:**
- ‡∏•‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô OCR texts ‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡πÑ‡∏õ‡∏à‡∏≤‡∏Å 300 ‡πÄ‡∏õ‡πá‡∏ô 100
- ‡∏à‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡∏•‡∏î token ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì 60-70%

---

### **‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2: ‡πÉ‡∏ä‡πâ Template ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏á‡πà‡∏≤‡∏¢‡∏Å‡∏ß‡πà‡∏≤**

#### **‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç API Request**

‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏à‡∏≤‡∏Å `template: "medical_receipt"` ‡πÄ‡∏õ‡πá‡∏ô `template: "receipt"`

```python
# ‡πÄ‡∏î‡∏¥‡∏°
result = pipeline.extract_from_text(ocr_texts, template="medical_receipt")

# ‡πÅ‡∏Å‡πâ‡πÄ‡∏õ‡πá‡∏ô
result = pipeline.extract_from_text(ocr_texts, template="receipt")
```

**‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢:**
- Template "receipt" ‡∏°‡∏µ prompt ‡∏™‡∏±‡πâ‡∏ô‡∏Å‡∏ß‡πà‡∏≤
- ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ billing items ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î

---

### **‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 3: ‡πÅ‡∏ö‡πà‡∏á OCR Text ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏≤‡∏¢‡∏™‡πà‡∏ß‡∏ô**

#### **‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç `ai_simple_extraction.py`**

‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á text ‡∏Å‡πà‡∏≠‡∏ô‡∏™‡πà‡∏á‡πÑ‡∏õ AI:

```python
def _create_simple_prompt(self, ocr_results: List[Dict[str, Any]], template: str = "medical_receipt") -> str:
    """Create simple prompt that asks for plain text extraction based on template"""
    
    # Format OCR text (text only, sorted by position)
    texts = []
    for result in ocr_results:
        text = result.get('text', '').strip()
        if text and len(text) > 1:
            texts.append(text)
    
    # ‚≠ê ‡πÄ‡∏û‡∏¥‡πà‡∏°: ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ text
    max_text_length = 100  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 100 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£
    texts = [t[:max_text_length] for t in texts]
    
    ocr_text = '\n'.join(texts[:self.max_ocr_results])
    
    # ‚≠ê ‡πÄ‡∏û‡∏¥‡πà‡∏°: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏£‡∏ß‡∏°
    max_total_chars = 5000  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏£‡∏ß‡∏°‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 5000 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£
    if len(ocr_text) > max_total_chars:
        ocr_text = ocr_text[:max_total_chars]
        logger.warning(f"OCR text truncated to {max_total_chars} characters")
    
    logger.info(f"OCR processing: {len(texts)} total texts, {len(ocr_text)} chars")
    
    # ... rest of the code
```

---

### **‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 4: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Error Message ‡∏à‡∏≤‡∏Å API**

#### **Code ‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß** ‚úÖ

‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡πÅ‡∏™‡∏î‡∏á error detail ‡∏à‡∏≤‡∏Å API ‡πÅ‡∏•‡πâ‡∏ß:

```python
else:
    error_detail = ""
    try:
        error_data = response.json()
        error_detail = f": {error_data}"
    except:
        error_detail = f": {response.text[:200]}"
    logger.warning(f"AI API returned status {response.status_code}{error_detail}")
```

**‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ:**
1. ‡∏£‡∏±‡∏ô API ‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á
2. ‡∏î‡∏π log ‡∏ß‡πà‡∏≤ error message ‡∏ö‡∏≠‡∏Å‡∏≠‡∏∞‡πÑ‡∏£
3. ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ï‡∏≤‡∏° error message

---

### **‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 5: ‡∏•‡∏î max_tokens**

#### **‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç `config.json`**

‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏à‡∏≤‡∏Å:
```json
{
  "ai_extraction": {
    "api": {
      "max_tokens": 8000
    }
  }
}
```

‡πÄ‡∏õ‡πá‡∏ô:
```json
{
  "ai_extraction": {
    "api": {
      "max_tokens": 4000
    }
  }
}
```

**‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢:**
- ‡∏•‡∏î max_tokens ‡∏ó‡∏µ‡πà‡∏Ç‡∏≠ response
- ‡∏ö‡∏≤‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á input + output tokens ‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô context window

---

## üß™ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç

### **‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1: ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç config.json**

```json
{
  "ai_extraction": {
    "api": {
      "endpoint": "http://10.5.19.205:8080/v1/chat/completions",
      "model": "qwen/qwen3-4b-2507",
      "timeout": 180,
      "max_retries": 2,
      "temperature": 0.1,
      "max_tokens": 4000
    },
    "prompt_optimization": {
      "text_only_mode": true,
      "max_ocr_results": 100,
      "sort_by_position": true,
      "filter_low_confidence": true,
      "confidence_threshold": 0.5
    }
  }
}
```

**‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô:**
- `max_tokens`: 8000 ‚Üí 4000
- `max_ocr_results`: 300 ‚Üí 100

### **‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2: Restart API Server**

```bash
# ‡∏´‡∏¢‡∏∏‡∏î API Server
Ctrl+C

# ‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÉ‡∏´‡∏°‡πà
python api_server.py
```

### **‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 3: ‡∏ó‡∏î‡∏™‡∏≠‡∏ö**

```bash
curl -X POST http://localhost:8000/extract/text \
  -H "Content-Type: application/json" \
  -d '{
    "ocr_texts": ["‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û", "HN: 04-20-006834"],
    "template": "receipt"
  }'
```

---

## üìä ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Token Usage

### **‡∏ß‡∏¥‡∏ò‡∏µ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Tokens ‡πÇ‡∏î‡∏¢‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì**

```python
# ‡∏™‡∏π‡∏ï‡∏£‡∏Ñ‡∏£‡πà‡∏≤‡∏ß‡πÜ
tokens_approx = len(text) / 4  # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©
tokens_approx = len(text) / 2  # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢

# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
text = "‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û ‡∏à‡∏±‡∏ô‡∏ó‡∏ö‡∏∏‡∏£‡∏µ HN: 04-20-006834"
chars = len(text)  # 48 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£
tokens = chars / 2  # ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì 24 tokens
```

### **Token Limits ‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•**

| Model | Context Window | Max Input | Max Output |
|-------|----------------|-----------|------------|
| qwen3-4b-2507 | 8,192 tokens | ~6,000 | ~2,000 |
| gpt-oss-20b | 4,096 tokens | ~3,000 | ~1,000 |

**‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:**
- Input + Output ‡∏ï‡πâ‡∏≠‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô Context Window
- ‡∏Ñ‡∏ß‡∏£‡πÄ‡∏´‡∏•‡∏∑‡∏≠ buffer 10-20% ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö system prompt

---

## üîç Debug Steps

### **1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Request File**

```bash
# ‡∏î‡∏π‡πÑ‡∏ü‡∏•‡πå request ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
cat output/ai_debug/requests/request_20251007_145313_6966fcd4.json

# ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£
cat output/ai_debug/requests/request_20251007_145313_6966fcd4.json | jq '.payload.messages[1].content' | wc -c
```

### **2. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö API ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á**

```bash
# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢ curl
curl -X POST http://10.5.19.205:8080/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "qwen/qwen3-4b-2507",
    "messages": [
      {"role": "system", "content": "You are helpful."},
      {"role": "user", "content": "Say hello"}
    ],
    "max_tokens": 100
  }'
```

### **3. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Log**

```bash
# ‡∏î‡∏π log real-time
tail -f logs/pipeline.log

# ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ error
grep "ERROR\|WARNING" logs/pipeline.log | tail -20
```

---

## ‚úÖ Solution ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ (Quick Fix)

### **‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç config.json ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ:**

```json
{
  "ai_extraction": {
    "api": {
      "max_tokens": 4000
    },
    "prompt_optimization": {
      "max_ocr_results": 80
    }
  }
}
```

### **Restart API Server:**

```bash
python api_server.py
```

### **‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á:**

```bash
curl -X POST http://localhost:8000/extract/text \
  -H "Content-Type: application/json" \
  -d @test_text_request.json
```

---

## üìû ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ

### **‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°:**

1. **API Server Status**
   ```bash
   curl http://10.5.19.205:8080/health
   ```

2. **Network Connection**
   ```bash
   ping 10.5.19.205
   ```

3. **Model Availability**
   ```bash
   curl http://10.5.19.205:8080/v1/models
   ```

4. **Check Logs on AI Server**
   - ‡∏î‡∏π log ‡∏ó‡∏µ‡πà AI server (`10.5.19.205`)
   - ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ error ‡∏≠‡∏∞‡πÑ‡∏£

---

## üéØ Prevention (‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤)

### **1. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Monitoring**

```python
# ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏ô ai_simple_extraction.py
def _create_simple_prompt(self, ...):
    # ...
    ocr_text = '\n'.join(texts[:self.max_ocr_results])
    
    # ‚≠ê ‡πÄ‡∏û‡∏¥‡πà‡∏° warning
    if len(ocr_text) > 5000:
        logger.warning(f"‚ö†Ô∏è  OCR text is long ({len(ocr_text)} chars), may cause API 400")
    
    return prompt
```

### **2. ‡πÉ‡∏ä‡πâ Validation**

```python
# ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡πà‡∏≠‡∏ô‡∏™‡πà‡∏á
def extract_simple(self, ocr_results: List[Dict[str, Any]], ...):
    # ...
    prompt = self._create_simple_prompt(ocr_results, template)
    
    # ‚≠ê ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß
    estimated_tokens = len(prompt) / 2  # ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì
    if estimated_tokens > 6000:
        raise ValueError(f"Prompt too long: {estimated_tokens} tokens (max: 6000)")
    
    # ...
```

### **3. Auto-Truncate**

```python
# ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
def _create_simple_prompt(self, ...):
    # ...
    ocr_text = '\n'.join(texts[:self.max_ocr_results])
    
    # ‚≠ê Auto-truncate
    MAX_CHARS = 5000
    if len(ocr_text) > MAX_CHARS:
        ocr_text = ocr_text[:MAX_CHARS]
        ocr_text += "\n\n[... text truncated ...]"
        logger.info(f"Auto-truncated to {MAX_CHARS} chars")
    
    return prompt
```

---

## üìã Checklist ‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç

- [ ] ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç `config.json` ‡∏•‡∏î `max_ocr_results` ‡πÄ‡∏õ‡πá‡∏ô 80-100
- [ ] ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç `config.json` ‡∏•‡∏î `max_tokens` ‡πÄ‡∏õ‡πá‡∏ô 4000
- [ ] Restart API server
- [ ] ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢ simple request
- [ ] ‡∏î‡∏π log ‡∏ß‡πà‡∏≤‡∏°‡∏µ error detail ‡∏≠‡∏∞‡πÑ‡∏£
- [ ] ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡∏•‡∏≠‡∏á template "receipt" ‡πÅ‡∏ó‡∏ô
- [ ] ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö AI API ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á

---

## üéì ‡∏™‡∏£‡∏∏‡∏õ

**‡∏õ‡∏±‡∏ç‡∏´‡∏≤:** AI API ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ 400 Bad Request

**‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏‡∏´‡∏•‡∏±‡∏Å:** Prompt/OCR text ‡∏¢‡∏≤‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô token limit

**‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ:**
1. ‚úÖ ‡∏•‡∏î `max_ocr_results` ‡∏à‡∏≤‡∏Å 300 ‚Üí 100
2. ‚úÖ ‡∏•‡∏î `max_tokens` ‡∏à‡∏≤‡∏Å 8000 ‚Üí 4000
3. ‚úÖ ‡πÉ‡∏ä‡πâ template ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏á‡πà‡∏≤‡∏¢‡∏Å‡∏ß‡πà‡∏≤
4. ‚úÖ Auto-truncate text ‡∏ó‡∏µ‡πà‡∏¢‡∏≤‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ

**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á:**
- API ‡∏à‡∏∞‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ 200 OK
- Extraction ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
- ‡πÑ‡∏°‡πà‡∏°‡∏µ retry

---

**Version:** 1.0  
**Created:** October 7, 2025  
**Status:** ‚úÖ Ready to Use

